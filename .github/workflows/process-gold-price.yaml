name: Process Gold Price Data

on:
  schedule:
    - cron: '0 */12 * * *' # Runs every 12 hours
  workflow_dispatch: # Allows manual triggering

jobs:
  process-data:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install google-cloud-pubsub google-cloud-bigquery google-cloud-storage

    - name: Authenticate to Google Cloud
      uses: 'google-github-actions/auth@v1'
      with:
        credentials_json: '${{ secrets.GCP_SA_KEY }}'

    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v1

    - name: Trigger Cloud Run Service
      run: |
        CLOUD_RUN_URL=$(gcloud run services describe gold-price-ingestion --region us-west1 --format='value(status.url)')
        curl -X GET ${CLOUD_RUN_URL}/fetch-and-publish

    - name: Run Spark Jobs
      run: |
        gcloud compute ssh spark-instance --zone us-west1-a --command "
        spark-submit \
        --master local[*] \
        clean_transform.py && \
        spark-submit \
        --master local[*] \
        load_to_bigquery.py
        "

    - name: Verify BigQuery Data
      run: |
        bq query --use_legacy_sql=false '
        SELECT COUNT(*) as row_count
        FROM `de-goldprice.gold_price_dataset.gold_prices`
        WHERE DATE(date) = DATE(CURRENT_TIMESTAMP())
        '

    env:
      PROJECT_ID: de-goldprice
      PUBSUB_TOPIC: gold-price
      BIGQUERY_DATASET: gold_price_dataset
      BIGQUERY_TABLE: gold_prices
      GOOGLE_APPLICATION_CREDENTIALS: ${{ steps.auth.outputs.credentials_file_path }}
name: Gold Price Data Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 0 * * *' # Runs at 00:00 UTC every day

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-west1

jobs:
  deploy:
    name: Deploy to GCP
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Setup Go
      uses: actions/setup-go@v2
      with:
        go-version: '1.21'

    - name: Setup Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create Service Account Key File
      run: |
        echo '${{ secrets.GCP_SA_KEY }}' > sa-key.json
        chmod 600 sa-key.json

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v1
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v1
      with:
        project_id: ${{ env.PROJECT_ID }}

    - name: Configure Docker
      run: |
        gcloud auth configure-docker gcr.io

    - name: Get latest version and increment
      id: get_version
      run: |
        LATEST_VERSION=$(gcloud container images list-tags gcr.io/${{ env.PROJECT_ID }}/gold-price-producer --format='get(tags)' --sort-by=~tags | grep '^v1\.0\.' | head -n 1)
        PATCH_VERSION=$(echo $LATEST_VERSION | cut -d. -f3)
        NEW_PATCH_VERSION=$((PATCH_VERSION + 1))
        NEW_VERSION="v1.0.$NEW_PATCH_VERSION"
        echo "NEW_VERSION=$NEW_VERSION" >> $GITHUB_OUTPUT

    - name: Build and Push New Version
      env:
        NEW_VERSION: ${{ steps.get_version.outputs.NEW_VERSION }}
      run: |
        docker build -t gcr.io/${{ env.PROJECT_ID }}/gold-price-producer:$NEW_VERSION -f Dockerfile-producer .
        docker push gcr.io/${{ env.PROJECT_ID }}/gold-price-producer:$NEW_VERSION

    - name: Upload code to GCS
      run: |
        gsutil cp *.py gs://de-goldprice-code/
        echo "Listing contents of GCS bucket:"
        gsutil ls gs://de-goldprice-code/

    - name: Deploy to Cloud Run
      env:
        NEW_VERSION: ${{ steps.get_version.outputs.NEW_VERSION }}
      run: |
        gcloud run deploy gold-price-ingestion \
          --image gcr.io/${{ env.PROJECT_ID }}/gold-price-producer:$NEW_VERSION \
          --region ${{ env.REGION }} \
          --set-env-vars GCS_BUCKET=gold-price-raw-data \
          --set-env-vars GOLD_API_KEY="${{ secrets.GOLD_API_KEY }}" \
          --set-env-vars GOLD_API_BASE_URL=https://www.goldapi.io/api \
          --set-env-vars GOOGLE_CLOUD_PROJECT=${{ env.PROJECT_ID }} \
          --set-env-vars PUBSUB_TOPIC=gold-price \
          --service-account goldprice-service-account@${{ env.PROJECT_ID }}.iam.gserviceaccount.com

    - name: Update DAG file
      run: |
        sed -i 's/from data_sources/from de_goldprice.data_sources/' dags/gold_price_dag.py
        sed -i 's/from pubsub_producer/from de_goldprice.pubsub_producer/' dags/gold_price_dag.py
        gsutil cp dags/gold_price_dag.py gs://us-west1-gold-price-compose-71bd680f-bucket/dags/

    - name: Install custom dependencies in Composer
      run: |
        gcloud composer environments update gold-price-composer \
          --location ${{ env.REGION }} \
          --update-pypi-packages-from-file requirements.txt

    - name: Configure SSH connection
      run: |
        SPARK_IP=$(gcloud compute instances describe spark-instance --zone ${{ env.REGION }}-a --format='get(networkInterfaces[0].accessConfigs[0].natIP)')
        gcloud composer environments run gold-price-composer \
          --location ${{ env.REGION }} \
          connections -- add 'spark_instance_ssh_hook' \
          --conn-type 'ssh' \
          --conn-host "$SPARK_IP" \
          --conn-login 'ubuntu' \
          --conn-port 22 \
          --conn-extra '{"key_file": "/home/airflow/gcs/data/spark_ssh_key"}'

    - name: Upload SSH key to Composer
      run: |
        echo "${{ secrets.SPARK_SSH_PRIVATE_KEY }}" | gcloud composer environments storage data import \
          --environment gold-price-composer \
          --location ${{ env.REGION }} \
          --destination spark_ssh_key

    - name: Install custom package in Composer
      run: |
        pip install . --target /tmp/de_goldprice
        zip -r /tmp/de_goldprice.zip /tmp/de_goldprice
        gcloud composer environments storage plugins import \
          --environment gold-price-composer \
          --location ${{ env.REGION }} \
          --source /tmp/de_goldprice.zip

    - name: Upload DAG to Cloud Composer
      run: |
        gcloud composer environments storage dags import \
          --environment gold-price-composer \
          --location ${{ env.REGION }} \
          --source dags/gold_price_dag.py

    - name: Trigger Airflow DAG
      run: |
        gcloud composer environments run gold-price-composer \
          --location ${{ env.REGION }} \
          dags trigger -- gold_price_pipeline

    - name: Verify BigQuery Data
      run: |
        bq query --use_legacy_sql=false '
        SELECT COUNT(*) as row_count
        FROM `de-goldprice.gold_price_dataset.gold_prices`
        WHERE DATE(date) = DATE(CURRENT_TIMESTAMP())
        '

    - name: Clean up old images
      run: |
        OLD_VERSIONS=$(gcloud container images list-tags gcr.io/${{ env.PROJECT_ID }}/gold-price-producer --format='get(tags)' --sort-by=~tags | tail -n +6)
        for version in $OLD_VERSIONS; do
          gcloud container images delete gcr.io/${{ env.PROJECT_ID }}/gold-price-producer:$version --quiet
        done